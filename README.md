# Langchain-RAG-Chat-with-your-Data
Langchain RAG LLM that retrieves contextual documents from an external dataset (chatbot that responds to queries based on the content of your documents)

# ğŸ¤– Langchain-RAG-Chat-with-your-Data

In this repo, we'll build a Langchain RAG LLM that retrieves contextual documents from an external dataset (chatbot that responds to queries based on the content of your documents).

### âš™ï¸The colab link to the code is found and (will also be included in this repo) [here.](https://colab.research.google.com/drive/1OR0dpmer4AFPwvKvA3e5dW8C_lU8o2D3?usp=sharing)

# âš™ï¸The Build Process (Deliverables)

### Build ğŸ—ï¸
* **Document Loading:** data loading, discovering over 80 unique loaders LangChain provides to access diverse data sources, including audio and video
* **Document Splitting**
* **Vector stores and embeddings:** vector store integrations within LangChain
* **Retrieval:** accessing and indexing data in the vector store
* **Question Answering:** build a one-pass question-answering solution.
* **Chat:** track and select pertinent information from conversations and data sources
